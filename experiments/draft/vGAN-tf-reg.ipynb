{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../dataset/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../dataset/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../dataset/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../dataset/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('../dataset/MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mb_size = 64\n",
    "Z_dim = 100\n",
    "X_dim = mnist.train.images.shape[1]\n",
    "y_dim = mnist.train.labels.shape[1]\n",
    "h_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_side = int(np.sqrt(X_dim))\n",
    "# DX_side = int(X_side/2)\n",
    "# DX_dim = int(X_dim/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = 0\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xavier_init(size):\n",
    "    in_dim = size[0]\n",
    "    xavier_stddev = 1. / tf.sqrt(in_dim / 2.)\n",
    "    return tf.random_normal(shape=size, stddev=xavier_stddev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geneartor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Z = tf.placeholder(tf.float32, shape=[None, Z_dim])\n",
    "\n",
    "G_W1 = tf.Variable(xavier_init([Z_dim, h_dim]))\n",
    "G_b1 = tf.Variable(tf.zeros(shape=[h_dim]))\n",
    "\n",
    "G_W2 = tf.Variable(xavier_init([h_dim, X_dim]))\n",
    "G_b2 = tf.Variable(tf.zeros(shape=[X_dim]))\n",
    "\n",
    "theta_G = [G_W1, G_W2, G_b1, G_b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(z):\n",
    "    G_h1 = tf.nn.relu(tf.matmul(z, G_W1) + G_b1)\n",
    "    G_log_prob = tf.matmul(G_h1, G_W2) + G_b2\n",
    "    G_prob = tf.nn.sigmoid(G_log_prob)\n",
    "\n",
    "    return G_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, X_dim])\n",
    "D_W1 = tf.Variable(xavier_init([X_dim, h_dim]))\n",
    "D_b1 = tf.Variable(tf.zeros(shape=[h_dim]))\n",
    "\n",
    "D_W2 = tf.Variable(xavier_init([h_dim, 1]))\n",
    "D_b2 = tf.Variable(tf.zeros(shape=[1]))\n",
    "\n",
    "theta_D = [D_W1, D_W2, D_b1, D_b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator(x):\n",
    "    D_h1 = tf.nn.relu(tf.matmul(x, D_W1) + D_b1)\n",
    "    D_logit = tf.matmul(D_h1, D_W2) + D_b2\n",
    "    D_prob = tf.nn.sigmoid(D_logit)\n",
    "\n",
    "    return D_prob, D_logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_Z(m, n):\n",
    "    return np.random.uniform(-1., 1., size=[m, n]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(samples):\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    gs = gridspec.GridSpec(4, 4)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(sample.reshape(28, 28), cmap='Greys_r')\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resize_image(sample, X_dim, X_side, DX_dim):\n",
    "    dim0 = tf.shape(sample)[0]\n",
    "    sample_reshaped = tf.reshape(sample, (dim0, X_side, X_side))\n",
    "    sample_resized = tf.slice(sample_reshaped, \n",
    "                         [0, 0, 0], [dim0, DX_side, DX_side])\n",
    "    sample_new = tf.reshape(sample_resized , [dim0, DX_dim])\n",
    "    return sample_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "wSet = np.zeros(X_dim).astype('float32')\n",
    "r = random.sample(range(1, X_dim), 200)\n",
    "wSet[r] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Pw = tf.constant(wSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pooling(sample, Pw):\n",
    "    dim0 = tf.shape(sample)[0]\n",
    "    B = tf.expand_dims(tf.ones([dim0]), 1) * Pw \n",
    "    sample_new = tf.multiply(sample, B)\n",
    "    return sample_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_full_sample = generator(Z)\n",
    "G_sample = pooling(G_full_sample, Pw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_real, D_logit_real = discriminator(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_fake, D_logit_fake = discriminator(G_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_loss_real = tf.reduce_mean(\n",
    "    tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "        logits=D_logit_real, labels=tf.ones_like(D_logit_real)))\n",
    "D_loss_fake = tf.reduce_mean(\n",
    "    tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "        logits=D_logit_fake, labels=tf.zeros_like(D_logit_fake)))\n",
    "D_loss = D_loss_real + D_loss_fake\n",
    "\n",
    "G_gan_loss = tf.reduce_mean(\n",
    "    tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "        logits=D_logit_fake, labels=tf.ones_like(D_logit_fake)))\n",
    "G_reg = tf.reduce_mean(tf.abs(G_full_sample)) \n",
    "alpha = 0.01\n",
    "G_loss = G_gan_loss + alpha * G_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_solver = tf.train.AdamOptimizer().minimize(D_loss, var_list=theta_D)\n",
    "G_solver = tf.train.AdamOptimizer().minimize(G_loss, var_list=theta_G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('out2/'):\n",
    "    os.makedirs('out2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0\n",
      "D loss: 1.364\n",
      "G_loss: 1.519\n",
      "\n",
      "Iter: 1000\n",
      "D loss: 0.05676\n",
      "G_loss: 5.61\n",
      "\n",
      "Iter: 2000\n",
      "D loss: 0.284\n",
      "G_loss: 3.512\n",
      "\n",
      "Iter: 3000\n",
      "D loss: 0.589\n",
      "G_loss: 2.21\n",
      "\n",
      "Iter: 4000\n",
      "D loss: 0.8708\n",
      "G_loss: 1.923\n",
      "\n",
      "Iter: 5000\n",
      "D loss: 0.9289\n",
      "G_loss: 1.935\n",
      "\n",
      "Iter: 6000\n",
      "D loss: 0.7484\n",
      "G_loss: 1.748\n",
      "\n",
      "Iter: 7000\n",
      "D loss: 0.7836\n",
      "G_loss: 2.072\n",
      "\n",
      "Iter: 8000\n",
      "D loss: 0.5342\n",
      "G_loss: 1.898\n",
      "\n",
      "Iter: 9000\n",
      "D loss: 0.7057\n",
      "G_loss: 2.896\n",
      "\n",
      "Iter: 10000\n",
      "D loss: 0.2874\n",
      "G_loss: 3.104\n",
      "\n",
      "Iter: 11000\n",
      "D loss: 0.1295\n",
      "G_loss: 3.919\n",
      "\n",
      "Iter: 12000\n",
      "D loss: 0.363\n",
      "G_loss: 2.746\n",
      "\n",
      "Iter: 13000\n",
      "D loss: 0.3146\n",
      "G_loss: 2.836\n",
      "\n",
      "Iter: 14000\n",
      "D loss: 0.6938\n",
      "G_loss: 1.903\n",
      "\n",
      "Iter: 15000\n",
      "D loss: 0.9354\n",
      "G_loss: 1.935\n",
      "\n",
      "Iter: 16000\n",
      "D loss: 0.9706\n",
      "G_loss: 1.804\n",
      "\n",
      "Iter: 17000\n",
      "D loss: 0.9168\n",
      "G_loss: 1.544\n",
      "\n",
      "Iter: 18000\n",
      "D loss: 0.9936\n",
      "G_loss: 1.291\n",
      "\n",
      "Iter: 19000\n",
      "D loss: 1.013\n",
      "G_loss: 1.277\n",
      "\n",
      "Iter: 20000\n",
      "D loss: 0.8552\n",
      "G_loss: 1.337\n",
      "\n",
      "Iter: 21000\n",
      "D loss: 1.023\n",
      "G_loss: 1.272\n",
      "\n",
      "Iter: 22000\n",
      "D loss: 0.8561\n",
      "G_loss: 1.349\n",
      "\n",
      "Iter: 23000\n",
      "D loss: 1.13\n",
      "G_loss: 1.309\n",
      "\n",
      "Iter: 24000\n",
      "D loss: 0.7758\n",
      "G_loss: 1.37\n",
      "\n",
      "Iter: 25000\n",
      "D loss: 1.022\n",
      "G_loss: 1.218\n",
      "\n",
      "Iter: 26000\n",
      "D loss: 1.162\n",
      "G_loss: 1.21\n",
      "\n",
      "Iter: 27000\n",
      "D loss: 1.011\n",
      "G_loss: 1.302\n",
      "\n",
      "Iter: 28000\n",
      "D loss: 1.026\n",
      "G_loss: 1.293\n",
      "\n",
      "Iter: 29000\n",
      "D loss: 1.192\n",
      "G_loss: 1.133\n",
      "\n",
      "Iter: 30000\n",
      "D loss: 0.9232\n",
      "G_loss: 1.126\n",
      "\n",
      "Iter: 31000\n",
      "D loss: 1.008\n",
      "G_loss: 1.097\n",
      "\n",
      "Iter: 32000\n",
      "D loss: 1.14\n",
      "G_loss: 1.366\n",
      "\n",
      "Iter: 33000\n",
      "D loss: 0.8834\n",
      "G_loss: 1.261\n",
      "\n",
      "Iter: 34000\n",
      "D loss: 1.111\n",
      "G_loss: 1.183\n",
      "\n",
      "Iter: 35000\n",
      "D loss: 0.8634\n",
      "G_loss: 1.366\n",
      "\n",
      "Iter: 36000\n",
      "D loss: 1.142\n",
      "G_loss: 1.151\n",
      "\n",
      "Iter: 37000\n",
      "D loss: 1.089\n",
      "G_loss: 1.359\n",
      "\n",
      "Iter: 38000\n",
      "D loss: 1.02\n",
      "G_loss: 1.142\n",
      "\n",
      "Iter: 39000\n",
      "D loss: 0.9661\n",
      "G_loss: 1.347\n",
      "\n",
      "Iter: 40000\n",
      "D loss: 0.9529\n",
      "G_loss: 1.206\n",
      "\n",
      "Iter: 41000\n",
      "D loss: 1.015\n",
      "G_loss: 1.25\n",
      "\n",
      "Iter: 42000\n",
      "D loss: 0.9767\n",
      "G_loss: 1.362\n",
      "\n",
      "Iter: 43000\n",
      "D loss: 0.939\n",
      "G_loss: 1.317\n",
      "\n",
      "Iter: 44000\n",
      "D loss: 0.9073\n",
      "G_loss: 1.476\n",
      "\n",
      "Iter: 45000\n",
      "D loss: 0.9904\n",
      "G_loss: 1.291\n",
      "\n",
      "Iter: 46000\n",
      "D loss: 0.9315\n",
      "G_loss: 1.364\n",
      "\n",
      "Iter: 47000\n",
      "D loss: 0.9826\n",
      "G_loss: 1.218\n",
      "\n",
      "Iter: 48000\n",
      "D loss: 0.9053\n",
      "G_loss: 1.384\n",
      "\n",
      "Iter: 49000\n",
      "D loss: 0.8223\n",
      "G_loss: 1.255\n",
      "\n",
      "Iter: 50000\n",
      "D loss: 0.9033\n",
      "G_loss: 1.408\n",
      "\n",
      "Iter: 51000\n",
      "D loss: 0.9276\n",
      "G_loss: 1.384\n",
      "\n",
      "Iter: 52000\n",
      "D loss: 1.078\n",
      "G_loss: 1.325\n",
      "\n",
      "Iter: 53000\n",
      "D loss: 0.9622\n",
      "G_loss: 1.433\n",
      "\n",
      "Iter: 54000\n",
      "D loss: 0.8652\n",
      "G_loss: 1.421\n",
      "\n",
      "Iter: 55000\n",
      "D loss: 0.9302\n",
      "G_loss: 1.63\n",
      "\n",
      "Iter: 56000\n",
      "D loss: 1.076\n",
      "G_loss: 1.314\n",
      "\n",
      "Iter: 57000\n",
      "D loss: 0.925\n",
      "G_loss: 1.318\n",
      "\n",
      "Iter: 58000\n",
      "D loss: 1.008\n",
      "G_loss: 1.226\n",
      "\n",
      "Iter: 59000\n",
      "D loss: 1.042\n",
      "G_loss: 1.613\n",
      "\n",
      "Iter: 60000\n",
      "D loss: 0.8018\n",
      "G_loss: 1.587\n",
      "\n",
      "Iter: 61000\n",
      "D loss: 0.9068\n",
      "G_loss: 1.851\n",
      "\n",
      "Iter: 62000\n",
      "D loss: 1.033\n",
      "G_loss: 1.282\n",
      "\n",
      "Iter: 63000\n",
      "D loss: 0.9558\n",
      "G_loss: 1.548\n",
      "\n",
      "Iter: 64000\n",
      "D loss: 0.9854\n",
      "G_loss: 1.598\n",
      "\n",
      "Iter: 65000\n",
      "D loss: 0.951\n",
      "G_loss: 1.552\n",
      "\n",
      "Iter: 66000\n",
      "D loss: 0.8667\n",
      "G_loss: 1.186\n",
      "\n",
      "Iter: 67000\n",
      "D loss: 0.8891\n",
      "G_loss: 1.574\n",
      "\n",
      "Iter: 68000\n",
      "D loss: 0.8933\n",
      "G_loss: 1.564\n",
      "\n",
      "Iter: 69000\n",
      "D loss: 0.9321\n",
      "G_loss: 1.508\n",
      "\n",
      "Iter: 70000\n",
      "D loss: 0.8511\n",
      "G_loss: 1.514\n",
      "\n",
      "Iter: 71000\n",
      "D loss: 1.005\n",
      "G_loss: 1.755\n",
      "\n",
      "Iter: 72000\n",
      "D loss: 1.104\n",
      "G_loss: 1.479\n",
      "\n",
      "Iter: 73000\n",
      "D loss: 0.8871\n",
      "G_loss: 1.504\n",
      "\n",
      "Iter: 74000\n",
      "D loss: 1.12\n",
      "G_loss: 1.72\n",
      "\n",
      "Iter: 75000\n",
      "D loss: 1.003\n",
      "G_loss: 1.519\n",
      "\n",
      "Iter: 76000\n",
      "D loss: 0.9792\n",
      "G_loss: 1.542\n",
      "\n",
      "Iter: 77000\n",
      "D loss: 1.105\n",
      "G_loss: 1.357\n",
      "\n",
      "Iter: 78000\n",
      "D loss: 1.01\n",
      "G_loss: 1.624\n",
      "\n",
      "Iter: 79000\n",
      "D loss: 0.9433\n",
      "G_loss: 1.481\n",
      "\n",
      "Iter: 80000\n",
      "D loss: 0.8813\n",
      "G_loss: 1.583\n",
      "\n",
      "Iter: 81000\n",
      "D loss: 0.9\n",
      "G_loss: 1.465\n",
      "\n",
      "Iter: 82000\n",
      "D loss: 0.7475\n",
      "G_loss: 1.583\n",
      "\n",
      "Iter: 83000\n",
      "D loss: 1.044\n",
      "G_loss: 1.673\n",
      "\n",
      "Iter: 84000\n",
      "D loss: 0.8606\n",
      "G_loss: 1.421\n",
      "\n",
      "Iter: 85000\n",
      "D loss: 0.8011\n",
      "G_loss: 1.435\n",
      "\n",
      "Iter: 86000\n",
      "D loss: 0.9143\n",
      "G_loss: 1.464\n",
      "\n",
      "Iter: 87000\n",
      "D loss: 0.8559\n",
      "G_loss: 1.221\n",
      "\n",
      "Iter: 88000\n",
      "D loss: 0.916\n",
      "G_loss: 1.411\n",
      "\n",
      "Iter: 89000\n",
      "D loss: 0.951\n",
      "G_loss: 1.592\n",
      "\n",
      "Iter: 90000\n",
      "D loss: 0.9239\n",
      "G_loss: 1.583\n",
      "\n",
      "Iter: 91000\n",
      "D loss: 0.8707\n",
      "G_loss: 1.476\n",
      "\n",
      "Iter: 92000\n",
      "D loss: 0.8265\n",
      "G_loss: 1.393\n",
      "\n",
      "Iter: 93000\n",
      "D loss: 0.9133\n",
      "G_loss: 1.67\n",
      "\n",
      "Iter: 94000\n",
      "D loss: 0.9892\n",
      "G_loss: 1.543\n",
      "\n",
      "Iter: 95000\n",
      "D loss: 0.8974\n",
      "G_loss: 1.337\n",
      "\n",
      "Iter: 96000\n",
      "D loss: 0.8265\n",
      "G_loss: 1.731\n",
      "\n",
      "Iter: 97000\n",
      "D loss: 0.9921\n",
      "G_loss: 1.589\n",
      "\n",
      "Iter: 98000\n",
      "D loss: 0.9394\n",
      "G_loss: 1.713\n",
      "\n",
      "Iter: 99000\n",
      "D loss: 0.9071\n",
      "G_loss: 1.685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for it in range(100000):\n",
    "    if it % 1000 == 0:\n",
    "        samples = sess.run(G_full_sample, \n",
    "                   feed_dict={Z: sample_Z(16, Z_dim)})\n",
    "        fig = plot(samples)\n",
    "        plt.savefig('out2/{}.png'.format(str(i).zfill(3)), \n",
    "                    bbox_inches='tight')\n",
    "        i += 1\n",
    "        plt.close(fig)\n",
    "\n",
    "    X_full, _ = mnist.train.next_batch(mb_size)\n",
    "    dim0 = np.shape(X_full)[0]\n",
    "    p = np.ones([dim0, 1]) * wSet \n",
    "    X_mb = np.multiply(X_full, p) \n",
    "\n",
    "    _, D_loss_curr = sess.run([D_solver, D_loss], \n",
    "                  feed_dict={X: X_mb, Z: sample_Z(mb_size, Z_dim)})\n",
    "    _, G_loss_curr = sess.run([G_solver, G_loss], \n",
    "                  feed_dict={Z: sample_Z(mb_size, Z_dim)})\n",
    "\n",
    "    if it % 1000 == 0:\n",
    "        print('Iter: {}'.format(it))\n",
    "        print('D loss: {:.4}'. format(D_loss_curr))\n",
    "        print('G_loss: {:.4}'.format(G_loss_curr))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf3",
   "language": "python",
   "name": "tf3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
