{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csvFile = pd.read_csv('../dataset/data_cog.csv')\n",
    "data = csvFile.values\n",
    "Xdata = data[:, :-5] \n",
    "Xdata = Xdata / np.linalg.norm(Xdata, 2)\n",
    "ydata = data[:, -4:-1] \n",
    "ydata = ydata / np.linalg.norm(ydata, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(n, d) = Xdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_train = n // 2\n",
    "n_val = n // 10\n",
    "\n",
    "X_train = Xdata[:n_train]\n",
    "X_val   = Xdata[n_train:n_train+n_val]\n",
    "X_test  = Xdata[n_train+n_val:]\n",
    "\n",
    "y_train = ydata[:n_train]\n",
    "y_val   = ydata[n_train:n_train+n_val]\n",
    "y_test  = ydata[n_train+n_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_size = \n",
    "Z_dim = d\n",
    "X_dim = ydata.shape[1]\n",
    "y_dim = 1\n",
    "h_dim = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = 0\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xavier_init(size):\n",
    "    in_dim = size[0]\n",
    "    xavier_stddev = 1. / tf.sqrt(in_dim / 2.)\n",
    "    return tf.random_normal(shape=size, stddev=xavier_stddev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geneartor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Z = tf.placeholder(tf.float32, shape=[None, Z_dim])\n",
    "\n",
    "G_W1 = tf.Variable(xavier_init([Z_dim, h_dim]))\n",
    "G_b1 = tf.Variable(tf.zeros(shape=[h_dim]))\n",
    "\n",
    "G_W2 = tf.Variable(xavier_init([h_dim, X_dim]))\n",
    "G_b2 = tf.Variable(tf.zeros(shape=[X_dim]))\n",
    "\n",
    "theta_G = [G_W1, G_W2, G_b1, G_b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(z):\n",
    "    G_h1 = tf.nn.relu(tf.matmul(z, G_W1) + G_b1)\n",
    "    G_log_prob = tf.matmul(G_h1, G_W2) + G_b2\n",
    "    G_prob = tf.nn.relu(G_log_prob)\n",
    "\n",
    "    return G_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, X_dim])\n",
    "D_W1 = tf.Variable(xavier_init([X_dim, h_dim]))\n",
    "D_b1 = tf.Variable(tf.zeros(shape=[h_dim]))\n",
    "\n",
    "D_W2 = tf.Variable(xavier_init([h_dim, 1]))\n",
    "D_b2 = tf.Variable(tf.zeros(shape=[1]))\n",
    "\n",
    "theta_D = [D_W1, D_W2, D_b1, D_b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator(x):\n",
    "    D_h1 = tf.nn.relu(tf.matmul(x, D_W1) + D_b1)\n",
    "    D_logit = tf.matmul(D_h1, D_W2) + D_b2\n",
    "    D_prob = tf.nn.sigmoid(D_logit)\n",
    "\n",
    "    return D_prob, D_logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_Z(m, n):\n",
    "    return np.random.uniform(-1., 1., size=[m, n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot(samples):\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    gs = gridspec.GridSpec(4, 4)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(sample.reshape(28, 28), cmap='Greys_r')\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G_sample = generator(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_real, D_logit_real = discriminator(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_fake, D_logit_fake = discriminator(G_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_loss_real = tf.reduce_mean(\n",
    "    tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "        logits=D_logit_real, labels=tf.ones_like(D_logit_real)))\n",
    "D_loss_fake = tf.reduce_mean(\n",
    "    tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "        logits=D_logit_fake, labels=tf.zeros_like(D_logit_fake)))\n",
    "D_loss = D_loss_real + D_loss_fake\n",
    "\n",
    "G_loss = tf.reduce_mean(\n",
    "    tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "        logits=D_logit_fake, labels=tf.ones_like(D_logit_fake)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_solver = tf.train.AdamOptimizer().minimize(D_loss, var_list=theta_D)\n",
    "G_solver = tf.train.AdamOptimizer().minimize(G_loss, var_list=theta_G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0\n",
      "D loss: 1.388\n",
      "G_loss: 0.6925\n",
      "\n",
      "Iter: 100\n",
      "D loss: 1.295\n",
      "G_loss: 0.736\n",
      "\n",
      "Iter: 200\n",
      "D loss: 1.236\n",
      "G_loss: 0.7753\n",
      "\n",
      "Iter: 300\n",
      "D loss: 1.146\n",
      "G_loss: 0.8247\n",
      "\n",
      "Iter: 400\n",
      "D loss: 1.044\n",
      "G_loss: 0.901\n",
      "\n",
      "Iter: 500\n",
      "D loss: 0.9468\n",
      "G_loss: 1.003\n",
      "\n",
      "Iter: 600\n",
      "D loss: 0.8342\n",
      "G_loss: 1.119\n",
      "\n",
      "Iter: 700\n",
      "D loss: 0.6985\n",
      "G_loss: 1.237\n",
      "\n",
      "Iter: 800\n",
      "D loss: 0.6163\n",
      "G_loss: 1.324\n",
      "\n",
      "Iter: 900\n",
      "D loss: 0.5801\n",
      "G_loss: 1.454\n",
      "\n",
      "Iter: 1000\n",
      "D loss: 0.4566\n",
      "G_loss: 1.616\n",
      "\n",
      "Iter: 1100\n",
      "D loss: 0.3125\n",
      "G_loss: 1.76\n",
      "\n",
      "Iter: 1200\n",
      "D loss: 0.4072\n",
      "G_loss: 1.919\n",
      "\n",
      "Iter: 1300\n",
      "D loss: 0.268\n",
      "G_loss: 2.068\n",
      "\n",
      "Iter: 1400\n",
      "D loss: 0.2814\n",
      "G_loss: 2.157\n",
      "\n",
      "Iter: 1500\n",
      "D loss: 0.2492\n",
      "G_loss: 2.29\n",
      "\n",
      "Iter: 1600\n",
      "D loss: 0.2544\n",
      "G_loss: 2.452\n",
      "\n",
      "Iter: 1700\n",
      "D loss: 0.1572\n",
      "G_loss: 2.548\n",
      "\n",
      "Iter: 1800\n",
      "D loss: 0.1397\n",
      "G_loss: 2.538\n",
      "\n",
      "Iter: 1900\n",
      "D loss: 0.1153\n",
      "G_loss: 2.711\n",
      "\n",
      "Iter: 2000\n",
      "D loss: 0.108\n",
      "G_loss: 2.875\n",
      "\n",
      "Iter: 2100\n",
      "D loss: 0.06953\n",
      "G_loss: 3.045\n",
      "\n",
      "Iter: 2200\n",
      "D loss: 0.09538\n",
      "G_loss: 3.015\n",
      "\n",
      "Iter: 2300\n",
      "D loss: 0.1064\n",
      "G_loss: 3.22\n",
      "\n",
      "Iter: 2400\n",
      "D loss: 0.07705\n",
      "G_loss: 3.265\n",
      "\n",
      "Iter: 2500\n",
      "D loss: 0.05968\n",
      "G_loss: 3.374\n",
      "\n",
      "Iter: 2600\n",
      "D loss: 0.06229\n",
      "G_loss: 3.424\n",
      "\n",
      "Iter: 2700\n",
      "D loss: 0.06046\n",
      "G_loss: 3.554\n",
      "\n",
      "Iter: 2800\n",
      "D loss: 0.04047\n",
      "G_loss: 3.57\n",
      "\n",
      "Iter: 2900\n",
      "D loss: 0.04536\n",
      "G_loss: 3.58\n",
      "\n",
      "Iter: 3000\n",
      "D loss: 0.1468\n",
      "G_loss: 3.794\n",
      "\n",
      "Iter: 3100\n",
      "D loss: 0.05483\n",
      "G_loss: 3.633\n",
      "\n",
      "Iter: 3200\n",
      "D loss: 0.04216\n",
      "G_loss: 3.906\n",
      "\n",
      "Iter: 3300\n",
      "D loss: 0.02401\n",
      "G_loss: 3.99\n",
      "\n",
      "Iter: 3400\n",
      "D loss: 0.03498\n",
      "G_loss: 4.177\n",
      "\n",
      "Iter: 3500\n",
      "D loss: 0.02137\n",
      "G_loss: 4.022\n",
      "\n",
      "Iter: 3600\n",
      "D loss: 0.01822\n",
      "G_loss: 4.26\n",
      "\n",
      "Iter: 3700\n",
      "D loss: 0.02277\n",
      "G_loss: 4.295\n",
      "\n",
      "Iter: 3800\n",
      "D loss: 0.01975\n",
      "G_loss: 4.375\n",
      "\n",
      "Iter: 3900\n",
      "D loss: 0.01959\n",
      "G_loss: 4.297\n",
      "\n",
      "Iter: 4000\n",
      "D loss: 0.02161\n",
      "G_loss: 4.289\n",
      "\n",
      "Iter: 4100\n",
      "D loss: 0.01561\n",
      "G_loss: 4.485\n",
      "\n",
      "Iter: 4200\n",
      "D loss: 0.01243\n",
      "G_loss: 4.491\n",
      "\n",
      "Iter: 4300\n",
      "D loss: 0.016\n",
      "G_loss: 4.622\n",
      "\n",
      "Iter: 4400\n",
      "D loss: 0.01188\n",
      "G_loss: 4.551\n",
      "\n",
      "Iter: 4500\n",
      "D loss: 0.01161\n",
      "G_loss: 4.761\n",
      "\n",
      "Iter: 4600\n",
      "D loss: 0.08823\n",
      "G_loss: 4.882\n",
      "\n",
      "Iter: 4700\n",
      "D loss: 0.00953\n",
      "G_loss: 4.957\n",
      "\n",
      "Iter: 4800\n",
      "D loss: 0.009324\n",
      "G_loss: 4.898\n",
      "\n",
      "Iter: 4900\n",
      "D loss: 0.01767\n",
      "G_loss: 5.073\n",
      "\n",
      "Iter: 5000\n",
      "D loss: 0.0183\n",
      "G_loss: 5.099\n",
      "\n",
      "Iter: 5100\n",
      "D loss: 0.01571\n",
      "G_loss: 5.063\n",
      "\n",
      "Iter: 5200\n",
      "D loss: 0.008438\n",
      "G_loss: 5.129\n",
      "\n",
      "Iter: 5300\n",
      "D loss: 0.006662\n",
      "G_loss: 5.029\n",
      "\n",
      "Iter: 5400\n",
      "D loss: 0.008776\n",
      "G_loss: 5.187\n",
      "\n",
      "Iter: 5500\n",
      "D loss: 0.006561\n",
      "G_loss: 5.227\n",
      "\n",
      "Iter: 5600\n",
      "D loss: 0.007925\n",
      "G_loss: 5.055\n",
      "\n",
      "Iter: 5700\n",
      "D loss: 0.006475\n",
      "G_loss: 5.104\n",
      "\n",
      "Iter: 5800\n",
      "D loss: 0.005222\n",
      "G_loss: 5.533\n",
      "\n",
      "Iter: 5900\n",
      "D loss: 0.005644\n",
      "G_loss: 5.193\n",
      "\n",
      "Iter: 6000\n",
      "D loss: 0.004923\n",
      "G_loss: 5.588\n",
      "\n",
      "Iter: 6100\n",
      "D loss: 0.003758\n",
      "G_loss: 5.609\n",
      "\n",
      "Iter: 6200\n",
      "D loss: 0.005371\n",
      "G_loss: 5.364\n",
      "\n",
      "Iter: 6300\n",
      "D loss: 0.004587\n",
      "G_loss: 5.67\n",
      "\n",
      "Iter: 6400\n",
      "D loss: 0.004191\n",
      "G_loss: 5.556\n",
      "\n",
      "Iter: 6500\n",
      "D loss: 0.007285\n",
      "G_loss: 5.694\n",
      "\n",
      "Iter: 6600\n",
      "D loss: 0.004132\n",
      "G_loss: 5.68\n",
      "\n",
      "Iter: 6700\n",
      "D loss: 0.04091\n",
      "G_loss: 5.831\n",
      "\n",
      "Iter: 6800\n",
      "D loss: 0.002192\n",
      "G_loss: 6.144\n",
      "\n",
      "Iter: 6900\n",
      "D loss: 0.003147\n",
      "G_loss: 5.773\n",
      "\n",
      "Iter: 7000\n",
      "D loss: 0.002667\n",
      "G_loss: 6.139\n",
      "\n",
      "Iter: 7100\n",
      "D loss: 0.003958\n",
      "G_loss: 5.997\n",
      "\n",
      "Iter: 7200\n",
      "D loss: 0.002274\n",
      "G_loss: 6.287\n",
      "\n",
      "Iter: 7300\n",
      "D loss: 0.00273\n",
      "G_loss: 6.108\n",
      "\n",
      "Iter: 7400\n",
      "D loss: 0.02789\n",
      "G_loss: 5.943\n",
      "\n",
      "Iter: 7500\n",
      "D loss: 0.001593\n",
      "G_loss: 6.446\n",
      "\n",
      "Iter: 7600\n",
      "D loss: 0.02623\n",
      "G_loss: 5.993\n",
      "\n",
      "Iter: 7700\n",
      "D loss: 0.002068\n",
      "G_loss: 6.192\n",
      "\n",
      "Iter: 7800\n",
      "D loss: 0.001757\n",
      "G_loss: 6.445\n",
      "\n",
      "Iter: 7900\n",
      "D loss: 0.001913\n",
      "G_loss: 6.395\n",
      "\n",
      "Iter: 8000\n",
      "D loss: 0.002496\n",
      "G_loss: 6.098\n",
      "\n",
      "Iter: 8100\n",
      "D loss: 0.002645\n",
      "G_loss: 6.057\n",
      "\n",
      "Iter: 8200\n",
      "D loss: 0.001874\n",
      "G_loss: 6.396\n",
      "\n",
      "Iter: 8300\n",
      "D loss: 0.00173\n",
      "G_loss: 6.712\n",
      "\n",
      "Iter: 8400\n",
      "D loss: 0.001606\n",
      "G_loss: 6.451\n",
      "\n",
      "Iter: 8500\n",
      "D loss: 0.001477\n",
      "G_loss: 6.747\n",
      "\n",
      "Iter: 8600\n",
      "D loss: 0.001394\n",
      "G_loss: 6.589\n",
      "\n",
      "Iter: 8700\n",
      "D loss: 0.001589\n",
      "G_loss: 6.585\n",
      "\n",
      "Iter: 8800\n",
      "D loss: 0.002215\n",
      "G_loss: 6.541\n",
      "\n",
      "Iter: 8900\n",
      "D loss: 0.001179\n",
      "G_loss: 6.81\n",
      "\n",
      "Iter: 9000\n",
      "D loss: 0.02094\n",
      "G_loss: 6.935\n",
      "\n",
      "Iter: 9100\n",
      "D loss: 0.001088\n",
      "G_loss: 6.876\n",
      "\n",
      "Iter: 9200\n",
      "D loss: 0.001203\n",
      "G_loss: 6.774\n",
      "\n",
      "Iter: 9300\n",
      "D loss: 0.001504\n",
      "G_loss: 6.905\n",
      "\n",
      "Iter: 9400\n",
      "D loss: 0.001037\n",
      "G_loss: 6.945\n",
      "\n",
      "Iter: 9500\n",
      "D loss: 0.001056\n",
      "G_loss: 6.865\n",
      "\n",
      "Iter: 9600\n",
      "D loss: 0.000773\n",
      "G_loss: 7.221\n",
      "\n",
      "Iter: 9700\n",
      "D loss: 0.0007597\n",
      "G_loss: 7.196\n",
      "\n",
      "Iter: 9800\n",
      "D loss: 0.001006\n",
      "G_loss: 6.911\n",
      "\n",
      "Iter: 9900\n",
      "D loss: 0.001307\n",
      "G_loss: 6.997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for it in range(10000):\n",
    "    wSet = random.sample(range(n), mb_size)\n",
    "    y_mb = ydata[wSet, :]\n",
    "    _, D_loss_curr = sess.run([D_solver, D_loss], \n",
    "                  feed_dict={X: y_mb, Z: Xdata[wSet, :]})\n",
    "    _, G_loss_curr = sess.run([G_solver, G_loss], \n",
    "                  feed_dict={Z: Xdata[wSet, :]})\n",
    "\n",
    "    if it % 100 == 0:\n",
    "        print('Iter: {}'.format(it))\n",
    "        print('D loss: {:.4}'. format(D_loss_curr))\n",
    "        print('G_loss: {:.4}'.format(G_loss_curr))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = sess.run(generator(Z), feed_dict={Z: X_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -785.33 ,  -357.47 ,   -71.218],\n",
       "       [ -660.46 ,  -176.41 ,   -32.398],\n",
       "       [ -602.03 ,  -346.18 ,   -53.077],\n",
       "       [ -744.64 ,  -190.4  ,   -35.72 ],\n",
       "       [-1019.   ,  -313.032,   -48.002],\n",
       "       [ -877.8  ,  -480.89 ,   -60.402],\n",
       "       [ -958.32 ,  -335.36 ,   -55.685],\n",
       "       [ -588.27 ,  -304.72 ,   -44.938],\n",
       "       [ -402.79 ,  -352.21 ,   -59.156],\n",
       "       [ -884.57 ,  -394.56 ,   -64.998],\n",
       "       [ -536.   ,  -578.   ,   -62.   ],\n",
       "       [ -849.52 ,  -335.36 ,   -51.296],\n",
       "       [ -510.2  ,  -346.69 ,   -57.175],\n",
       "       [ -604.77 ,  -201.52 ,   -34.264],\n",
       "       [ -901.87 ,  -306.49 ,   -50.725],\n",
       "       [ -786.02 ,  -354.84 ,   -63.653],\n",
       "       [ -749.59 ,  -241.02 ,   -39.433],\n",
       "       [ -699.   ,  -270.023,   -43.907],\n",
       "       [ -357.26 ,  -559.41 ,   -66.142],\n",
       "       [-1006.2  ,  -250.76 ,   -37.874],\n",
       "       [ -270.25 ,  -554.23 ,   -83.881],\n",
       "       [ -845.   ,  -296.   ,   -33.   ],\n",
       "       [ -621.   ,  -199.162,   -35.513],\n",
       "       [ -988.09 ,  -303.47 ,   -42.275],\n",
       "       [ -862.75 ,  -318.14 ,   -44.035],\n",
       "       [ -670.09 ,  -341.44 ,   -44.698],\n",
       "       [ -826.   ,  -100.188,   -85.35 ],\n",
       "       [ -749.33 ,  -210.3  ,   -37.523],\n",
       "       [ -378.74 ,  -614.99 ,   -78.11 ],\n",
       "       [ -763.   ,  -186.   ,   -25.   ],\n",
       "       [ -265.08 ,  -365.41 ,   -56.01 ],\n",
       "       [ -854.34 ,  -241.29 ,   -42.211],\n",
       "       [ -564.   ,  -188.828,   -33.462],\n",
       "       [ -723.21 ,  -312.81 ,   -48.215],\n",
       "       [ -687.44 ,  -163.99 ,   -26.598],\n",
       "       [ -534.86 ,  -501.03 ,   -67.831],\n",
       "       [ -713.82 ,  -227.41 ,   -35.779],\n",
       "       [ -647.43 ,  -384.23 ,   -63.211],\n",
       "       [ -668.97 ,  -144.16 ,   -22.737],\n",
       "       [ -894.22 ,  -367.62 ,   -53.257],\n",
       "       [ -742.52 ,  -349.9  ,   -46.77 ],\n",
       "       [ -834.64 ,  -304.41 ,   -49.163],\n",
       "       [ -854.   ,  -522.079,   -66.261],\n",
       "       [-1129.4  ,  -454.68 ,   -65.868],\n",
       "       [ -673.93 ,  -470.43 ,   -66.445],\n",
       "       [ -432.39 ,  -617.42 ,   -88.189],\n",
       "       [ -951.16 ,  -450.12 ,   -68.837],\n",
       "       [ -766.22 ,  -245.71 ,   -35.145],\n",
       "       [ -651.72 ,  -326.29 ,   -50.283],\n",
       "       [ -913.   ,  -338.175,   -52.309],\n",
       "       [ -918.06 ,  -298.56 ,   -45.504],\n",
       "       [ -910.24 ,  -246.45 ,   -37.661],\n",
       "       [ -689.   ,  -185.468,   -27.568],\n",
       "       [ -889.   ,  -324.506,   -47.583],\n",
       "       [ -585.63 ,  -192.39 ,   -26.893],\n",
       "       [ -640.86 ,  -351.89 ,   -56.814],\n",
       "       [ -864.   ,  -429.258,   -64.902],\n",
       "       [ -853.   ,  -451.245,   -60.122],\n",
       "       [ -672.   ,  -193.424,   -27.741],\n",
       "       [-1089.   ,  -394.872,   -58.82 ],\n",
       "       [ -616.7  ,  -154.7  ,   -22.844],\n",
       "       [ -905.11 ,  -327.81 ,   -53.995],\n",
       "       [ -756.   ,  -321.   ,   -37.   ],\n",
       "       [ -519.   ,  -232.717,   -33.21 ],\n",
       "       [ -891.   ,  -380.386,   -25.277],\n",
       "       [ -498.38 ,  -393.7  ,   -57.104],\n",
       "       [ -891.   ,  -221.766,   -35.843],\n",
       "       [ -479.34 ,  -379.74 ,   -50.872],\n",
       "       [ -948.   ,  -543.673,   -68.005],\n",
       "       [ -758.   ,  -348.313,   -51.211],\n",
       "       [ -973.46 ,  -389.6  ,   -56.158],\n",
       "       [ -776.   ,  -295.226,   -46.657],\n",
       "       [ -752.   ,  -160.   ,   -22.   ]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_train - y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf3",
   "language": "python",
   "name": "tf3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
